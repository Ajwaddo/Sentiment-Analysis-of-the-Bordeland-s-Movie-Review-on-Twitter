{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   Tweet ID       Entity Sentiment  \\\n",
      "0      2401  Borderlands  Positive   \n",
      "1      2401  Borderlands  Positive   \n",
      "2      2401  Borderlands  Positive   \n",
      "3      2401  Borderlands  Positive   \n",
      "4      2401  Borderlands  Positive   \n",
      "\n",
      "                                       Tweet Content  \n",
      "0  I am coming to the borders and I will kill you...  \n",
      "1  im getting on borderlands and i will kill you ...  \n",
      "2  im coming on borderlands and i will murder you...  \n",
      "3  im getting on borderlands 2 and i will murder ...  \n",
      "4  im getting into borderlands and i can murder y...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('archive-2/twitter_training.csv', header=None)\n",
    "# Let's provide some generic column names based on the context.\n",
    "# From the tutorial descriptions, the columns are likely: Tweet ID, Entity, Sentiment, and Tweet Content.\n",
    "df.columns = ['Tweet ID', 'Entity', 'Sentiment', 'Tweet Content']\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/muhdajwd/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/muhdajwd/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/var/folders/18/lqmw5rjn0tx6csw1d8wpyj_m0000gn/T/ipykernel_81597/2481583278.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Tweet Content'].fillna('', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Tweet Content  \\\n",
      "0  I am coming to the borders and I will kill you...   \n",
      "1  im getting on borderlands and i will kill you ...   \n",
      "2  im coming on borderlands and i will murder you...   \n",
      "3  im getting on borderlands 2 and i will murder ...   \n",
      "4  im getting into borderlands and i can murder y...   \n",
      "\n",
      "               processed_text  \n",
      "0            come border kill  \n",
      "1      im get borderland kill  \n",
      "2   im come borderland murder  \n",
      "3  im get borderland 2 murder  \n",
      "4    im get borderland murder  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK data (if you haven't already)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# --- Preprocessing Steps ---\n",
    "\n",
    "# 1. Handle Missing Values\n",
    "df['Tweet Content'].fillna('', inplace=True)\n",
    "\n",
    "# 2. Lowercase Conversion\n",
    "df['cleaned_text'] = df['Tweet Content'].str.lower()\n",
    "\n",
    "# 3. Punctuation Removal\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "# 4. Tokenization\n",
    "df['tokenized_text'] = df['cleaned_text'].apply(word_tokenize)\n",
    "\n",
    "# 5. Stop Word Removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['tokenized_text'] = df['tokenized_text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "# 6. Stemming\n",
    "stemmer = PorterStemmer()\n",
    "df['stemmed_text'] = df['tokenized_text'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "# Join the stemmed words back into a single string\n",
    "df['processed_text'] = df['stemmed_text'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Display the DataFrame with the new processed text column\n",
    "print(df[['Tweet Content', 'processed_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df['processed_text']\n",
    "y = df['Sentiment']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize a TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000) # You can adjust max_features\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest Classifier...\n",
      "Random Forest training completed.\n",
      "\n",
      "Training Naive Bayes Classifier...\n",
      "Naive Bayes training completed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# --- Train Random Forest Classifier ---\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)  # n_jobs=-1 uses all available CPU cores\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "print(\"Random Forest training completed.\")\n",
    "\n",
    "# --- Train Naive Bayes Classifier ---\n",
    "print(\"\\nTraining Naive Bayes Classifier...\")\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "print(\"Naive Bayes training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Random Forest Evaluation ---\n",
      "Accuracy: 0.8800\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.95      0.80      0.87      2598\n",
      "    Negative       0.91      0.90      0.90      4509\n",
      "     Neutral       0.81      0.90      0.85      3664\n",
      "    Positive       0.88      0.89      0.89      4166\n",
      "\n",
      "    accuracy                           0.88     14937\n",
      "   macro avg       0.89      0.87      0.88     14937\n",
      "weighted avg       0.88      0.88      0.88     14937\n",
      "\n",
      "\n",
      "--- Naive Bayes Evaluation ---\n",
      "Accuracy: 0.6339\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.74      0.36      0.48      2598\n",
      "    Negative       0.61      0.80      0.70      4509\n",
      "     Neutral       0.66      0.51      0.58      3664\n",
      "    Positive       0.62      0.73      0.67      4166\n",
      "\n",
      "    accuracy                           0.63     14937\n",
      "   macro avg       0.66      0.60      0.61     14937\n",
      "weighted avg       0.65      0.63      0.62     14937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# --- Evaluate Random Forest Classifier ---\n",
    "print(\"\\n--- Random Forest Evaluation ---\")\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# --- Evaluate Naive Bayes Classifier ---\n",
    "print(\"\\n--- Naive Bayes Evaluation ---\")\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"Accuracy: {accuracy_nb:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Predictions on New Tweets ---\n",
      "Tweet: 'I am absolutely loving this new update, the developers did a fantastic job!'\n",
      "  - Random Forest Prediction: Positive\n",
      "  - Naive Bayes Prediction:     Positive\n",
      "\n",
      "Tweet: 'This is the worst game I have ever played, it's full of bugs and crashes constantly.'\n",
      "  - Random Forest Prediction: Negative\n",
      "  - Naive Bayes Prediction:     Negative\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text, model, vectorizer, stemmer_obj):\n",
    "    # Apply the same preprocessing steps\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    stop_words_set = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words_set]\n",
    "    tokens = [stemmer_obj.stem(word) for word in tokens]\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    # Vectorize the text using the fitted vectorizer\n",
    "    vectorized_text = vectorizer.transform([processed_text])\n",
    "    \n",
    "    # Predict the sentiment using the provided model\n",
    "    prediction = model.predict(vectorized_text)\n",
    "    \n",
    "    return prediction[0]\n",
    "\n",
    "# --- Example Usage ---\n",
    "new_tweet_positive = \"I am absolutely loving this new update, the developers did a fantastic job!\"\n",
    "new_tweet_negative = \"This is the worst game I have ever played, it's full of bugs and crashes constantly.\"\n",
    "\n",
    "print(\"\\n--- Predictions on New Tweets ---\")\n",
    "\n",
    "# Get predictions from both models for the positive tweet\n",
    "print(f\"Tweet: '{new_tweet_positive}'\")\n",
    "print(f\"  - Random Forest Prediction: {predict_sentiment(new_tweet_positive, rf_model, tfidf_vectorizer, stemmer)}\")\n",
    "print(f\"  - Naive Bayes Prediction:     {predict_sentiment(new_tweet_positive, nb_model, tfidf_vectorizer, stemmer)}\")\n",
    "\n",
    "# Get predictions from both models for the negative tweet\n",
    "print(f\"\\nTweet: '{new_tweet_negative}'\")\n",
    "print(f\"  - Random Forest Prediction: {predict_sentiment(new_tweet_negative, rf_model, tfidf_vectorizer, stemmer)}\")\n",
    "print(f\"  - Naive Bayes Prediction:     {predict_sentiment(new_tweet_negative, nb_model, tfidf_vectorizer, stemmer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 7: Generating Visualizations ---\n",
      "Saved confusion_matrix_random_forest.png\n",
      "Saved confusion_matrix_naive_bayes.png\n",
      "Saved f1_score_comparison.png\n",
      "Saved prediction_distribution_comparison.png\n"
     ]
    }
   ],
   "source": [
    "# --- Step 7: Visualizing Model Performance ---\n",
    "print(\"\\n--- Step 7: Generating Visualizations ---\")\n",
    "\n",
    "labels = sorted(y.unique())\n",
    "\n",
    "# Function to plot a confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name, labels):\n",
    "    mat = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(mat, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    filename = f'confusion_matrix_{model_name.lower().replace(\" \", \"_\")}.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    print(f\"Saved {filename}\")\n",
    "\n",
    "# Plot for Random Forest\n",
    "plot_confusion_matrix(y_test, y_pred_rf, 'Random Forest', labels)\n",
    "\n",
    "# Plot for Naive Bayes\n",
    "plot_confusion_matrix(y_test, y_pred_nb, 'Naive Bayes', labels)\n",
    "\n",
    "# Compare Performance Metrics (F1-Score)\n",
    "report_rf = classification_report(y_test, y_pred_rf, output_dict=True)\n",
    "report_nb = classification_report(y_test, y_pred_nb, output_dict=True)\n",
    "\n",
    "f1_rf = {label: report_rf[label]['f1-score'] for label in labels if label in report_rf}\n",
    "f1_nb = {label: report_nb[label]['f1-score'] for label in labels if label in report_nb}\n",
    "\n",
    "f1_df = pd.DataFrame({'Random Forest': f1_rf, 'Naive Bayes': f1_nb})\n",
    "f1_df.plot(kind='bar', figsize=(12, 7), rot=0)\n",
    "plt.title('F1-Score Comparison by Sentiment Class')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('f1_score_comparison.png')\n",
    "plt.close()\n",
    "print(\"Saved f1_score_comparison.png\")\n",
    "\n",
    "# Visualize Sentiment Distribution\n",
    "actual_counts = y_test.value_counts()\n",
    "predicted_rf_counts = pd.Series(y_pred_rf).value_counts()\n",
    "predicted_nb_counts = pd.Series(y_pred_nb).value_counts()\n",
    "\n",
    "dist_df = pd.DataFrame({\n",
    "    'Actual': actual_counts,\n",
    "    'Random Forest': predicted_rf_counts,\n",
    "    'Naive Bayes': predicted_nb_counts\n",
    "}).fillna(0).astype(int).loc[labels]\n",
    "\n",
    "dist_df.plot(kind='bar', figsize=(14, 8), rot=0)\n",
    "plt.title('Distribution of Sentiments in Test Set (Actual vs. Predicted)')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('prediction_distribution_comparison.png')\n",
    "plt.close()\n",
    "print(\"Saved prediction_distribution_comparison.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
